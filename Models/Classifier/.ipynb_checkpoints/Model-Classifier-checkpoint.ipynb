{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd57ac72-349d-4775-8ae1-f30585fa8019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from tqdm import tqdm  # For displaying progress bars during training/evaluation\n",
    "\n",
    "# Custom dataset for weather classification\n",
    "class WeatherClassifierDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None, train=True):\n",
    "        self.samples = []  # List to hold (image_path, label) tuples\n",
    "        self.transform = transform\n",
    "        mode = 'train' if train else 'test'  # Choose folder based on train/test mode\n",
    "\n",
    "        # Loop through the two classes: rain and haze\n",
    "        for label, (weather_type, subfolder) in enumerate([('rain', 'rainy'), ('haze', 'hazy')]):\n",
    "            folder = os.path.join(root_dir, weather_type, mode, subfolder)  # Construct full folder path\n",
    "            for img in os.listdir(folder):  # Iterate over all image files\n",
    "                self.samples.append((os.path.join(folder, img), label))  # Append full path and label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)  # Return total number of samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]  # Get image path and label at index\n",
    "        image = Image.open(img_path).convert('RGB')  # Load image and convert to RGB\n",
    "        if self.transform:\n",
    "            image = self.transform(image)  # Apply transformations if any\n",
    "        return image, label  # Return transformed image and label\n",
    "\n",
    "# Define root directory for the dataset\n",
    "root_dir = \"../Data\"\n",
    "\n",
    "# Define transformations for the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to 224x224 (suitable for ResNet)\n",
    "    transforms.ToTensor()  # Convert PIL image to tensor\n",
    "])\n",
    "\n",
    "# Create dataset instances for training and testing\n",
    "train_ds = WeatherClassifierDataset(root_dir, transform, train=True)\n",
    "test_ds = WeatherClassifierDataset(root_dir, transform, train=False)\n",
    "\n",
    "# Wrap datasets in DataLoader for batching and shuffling\n",
    "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True)  # Shuffle during training\n",
    "test_loader = DataLoader(test_ds, batch_size=16, shuffle=False)   # No shuffle during testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36405f60-7705-4149-b555-5ccbce82f088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda NVIDIA GeForce RTX 3050 Ti Laptop GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|███████████████████████████████████████████████████████| 1232/1232 [03:59<00:00,  5.15batch/s, loss=9e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 completed. Avg Loss: 0.0069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|████████████████████████████████████████████████████| 1232/1232 [03:20<00:00,  6.15batch/s, loss=3.48e-5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 completed. Avg Loss: 0.0042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8:   2%|█                                                      | 24/1232 [00:04<03:37,  5.55batch/s, loss=0.0026]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     25\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 26\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mset_postfix(loss\u001b[38;5;241m=\u001b[39mloss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m completed. Avg Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal_loss\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(train_loader)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Model Setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # Use GPU if available, else fallback to CPU\n",
    "print(\"Using device:\", device, torch.cuda.get_device_name())  # Print selected device\n",
    "\n",
    "# Load pre-trained ResNet18 model with ImageNet weights\n",
    "model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# Replace the final fully connected layer to match our binary classification task (rain vs haze)\n",
    "model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "\n",
    "# Load the model weights from a previously saved checkpoint (epoch 5)\n",
    "model.load_state_dict(torch.load(\"model_classifier_epoch5.pth\"))\n",
    "\n",
    "# Move model to the selected device (GPU or CPU)\n",
    "model.to(device)\n",
    "\n",
    "# Define the loss function (CrossEntropy for multi-class classification)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Use Adam optimizer with a learning rate of 1e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Training loop from epoch 5 to 9 (inclusive of 5, exclusive of 10)\n",
    "for epoch in range(5, 10):\n",
    "    model.train()  # Set model to training mode\n",
    "    total_loss = 0  # To accumulate loss over the epoch\n",
    "\n",
    "    # tqdm progress bar for training batches\n",
    "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}\", unit=\"batch\")\n",
    "\n",
    "    # Iterate over training data\n",
    "    for imgs, labels in pbar:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)  # Move data to device\n",
    "\n",
    "        outputs = model(imgs)  # Forward pass\n",
    "        loss = criterion(outputs, labels)  # Compute loss\n",
    "\n",
    "        optimizer.zero_grad()  # Clear previous gradients\n",
    "        loss.backward()        # Backpropagation\n",
    "        optimizer.step()       # Update model parameters\n",
    "\n",
    "        total_loss += loss.item()  # Accumulate loss\n",
    "\n",
    "        # Update progress bar with current batch loss\n",
    "        pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "    # Print average loss for the epoch\n",
    "    print(f\"Epoch {epoch+1} completed. Avg Loss: {total_loss / len(train_loader):.4f}\")\n",
    "    \n",
    "    # Save model state after each epoch for checkpointing\n",
    "    torch.save(model.state_dict(), f\"model_classifier_epoch{epoch+1}.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "806a8a04-cd11-44c1-bfa6-08157574b4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda NVIDIA GeForce RTX 3050 Ti Laptop GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|█████████████████████████████████████████████████████████████████| 238/238 [00:28<00:00,  8.34batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classifier Test Accuracy: 0.9889473684210527\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Rain       1.00      0.99      0.99      2800\n",
      "        Haze       0.96      1.00      0.98      1000\n",
      "\n",
      "    accuracy                           0.99      3800\n",
      "   macro avg       0.98      0.99      0.99      3800\n",
      "weighted avg       0.99      0.99      0.99      3800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import evaluation metrics\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from tqdm import tqdm  # For progress bar during evaluation\n",
    "\n",
    "# Reload the test dataset (ensuring consistency if test dataset was changed during training)\n",
    "test_dataset = WeatherClassifierDataset(root_dir, transform=transform, train=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)  # No shuffling for evaluation\n",
    "\n",
    "# Select device (GPU if available, else CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device, torch.cuda.get_device_name(device.index if device.index is not None else 0))\n",
    "\n",
    "# Load the model and modify the final layer for binary classification\n",
    "model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "model.fc = nn.Linear(model.fc.in_features, 2)\n",
    "\n",
    "# Load model weights from epoch 7 checkpoint\n",
    "model.load_state_dict(torch.load(\"model_classifier_epoch7.pth\"))\n",
    "model.to(device)  # Move model to selected device\n",
    "model.eval()      # Set model to evaluation mode (disables dropout, etc.)\n",
    "\n",
    "# Initialize lists to store all predictions and true labels\n",
    "all_preds, all_labels = [], []\n",
    "\n",
    "# Disable gradient calculation for inference (saves memory and improves speed)\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in tqdm(test_loader, desc=\"Evaluating\", unit=\"batch\"):\n",
    "        imgs = imgs.to(device)  # Move images to device\n",
    "        outputs = model(imgs)   # Forward pass\n",
    "        preds = torch.argmax(outputs, dim=1).cpu().numpy()  # Get predicted class indices\n",
    "        all_preds.extend(preds)  # Store predictions\n",
    "        all_labels.extend(labels.numpy())  # Store true labels\n",
    "\n",
    "# Print overall test accuracy\n",
    "print(\"\\nClassifier Test Accuracy:\", accuracy_score(all_labels, all_preds))\n",
    "\n",
    "# Print detailed classification report (precision, recall, F1-score)\n",
    "print(classification_report(all_labels, all_preds, target_names=[\"Rain\", \"Haze\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497ce2e1-f5fd-42de-84c7-cbf31f43d6bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
